{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embedding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUXq09LyjITQ"
      },
      "source": [
        "THIS CODE HELPS IN COLLECTING THE WORD VECTORS STORED IN EMBEDDING WHICH CAN THEN BE PLOTTED USING TENSORFLOW EMBEDDING PROJECTOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc47MeHIjHow"
      },
      "source": [
        "import keras \n",
        "new_model = keras.models.load_model(\"/content/drive/MyDrive/ENTHIRE/GRU_Model/29_model/\")          #load the model\n",
        "e = new_model.layers[1]                                                                            #saving the embedding layer as e\n",
        "weights = e.get_weights()[0]                                                                       #getting the weights of the embedding layer\n",
        "print(weights.shape)\n",
        "import pickle\n",
        "tokenizer = pickle.load(open(\"/content/drive/MyDrive/ENTHIRE/GRU_Model/tokenizer_file2.pkl\",\"rb\")) #importing the tokenizer\n",
        "word_index = tokenizer.word_index                                                                  #storing the word_index dictionery\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])                   #making a new dictionary index_to_word whose keys are indexes and values are their corresponding words\n",
        "import io\n",
        "vocab_size = 7686\n",
        "out_v = io.open('/content/drive/MyDrive/ENTHIRE/GRU_Model/vecs1.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('/content/drive/MyDrive/ENTHIRE/GRU_Model/meta1.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]                                                            #collecting the word corresponding to the index from reverse_word_index \n",
        "  embeddings = weights[word_num]                                                                 #collecting the embedding corresponding to the index\n",
        "  out_m.write(word + \"\\n\")                                                                       #saving the words and their vectors\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeTKWKQpjC55"
      },
      "source": [
        ""
      ]
    }
  ]
}